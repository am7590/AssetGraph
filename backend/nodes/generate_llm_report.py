import logging
import json
from backend.utils.llm_client import call_llm

logger = logging.getLogger(__name__)

def generate_llm_report_node(params):
    # Potential params for LLM call (e.g., model, length constraint)
    llm_model = params.get("model", "gpt-4o") # Default model

    async def node(state: dict) -> dict:
        node_name = "GenerateLLMReport"
        logger.info(f"Running {node_name} with params: {params}")
        current_errors = state.get("errors", [])
        report_update = {}
        new_errors = []

        # --- Gather Data from State for Prompt Context --- 
        ticker = state.get("current_ticker")
        # Ensure processed_financials is a dict, default to empty if None
        processed_financials = state.get("processed_financials") or {}
        income_summary = state.get("income_summary") # Generated by previous node

        # Extract specific pieces needed for the prompt
        profile_summary = processed_financials.get("profile_summary", {})
        latest_is = processed_financials.get("latest_income_statement", {})
        latest_bs = processed_financials.get("latest_balance_sheet_summary", {})
        company_name = profile_summary.get("companyName", ticker or "Unknown Company")

        # --- Build the Prompt --- 
        # TODO: Refine this prompt for better structure and detail
        prompt_context = f"""
Company Name: {company_name} ({ticker or 'N/A'})
Sector: {profile_summary.get('sector', 'N/A')}
Industry: {profile_summary.get('industry', 'N/A')}

Income Statement Summary (from previous step):
{income_summary or 'Not available.'}

Latest Income Statement Figures:
Date: {latest_is.get('date', 'N/A')}
Revenue: {latest_is.get('revenue', 'N/A')}
Gross Profit: {latest_is.get('grossProfit', 'N/A')}
Net Income: {latest_is.get('netIncome', 'N/A')}

Latest Balance Sheet Figures:
Date: {latest_bs.get('date', 'N/A')}
Total Assets: {latest_bs.get('totalAssets', 'N/A')}
Total Liabilities: {latest_bs.get('totalLiabilities', 'N/A')}
Total Equity: {latest_bs.get('totalEquity', 'N/A')} 
"""

        prompt = f"""
You are a professional financial analyst. Your task is to generate a concise, professional Markdown financial report summary for investors based ONLY on the following provided data. Do not invent any information not present in the context.

Use clear Markdown headings for structure (e.g., ## Company Overview, ## Financial Highlights).

Data Context:
---
{prompt_context}
---

Generate the Markdown report now.
"""

        # --- Call LLM and Update State --- 
        try:
            markdown_report = await call_llm(prompt, model=llm_model)
            
            # Check if LLM call itself returned an error message
            if markdown_report.startswith("Error:"):
                 logger.error(f"LLM call failed: {markdown_report}")
                 new_errors.append(markdown_report) # Add LLM error to list
                 report_update["markdown_report"] = "# Report Generation Failed\n\nLLM Error."
            else:
                report_update["markdown_report"] = markdown_report
                logger.info(f"LLM report generated successfully for {ticker}.")

        except Exception as e:
            error_msg = f"Error during LLM report generation call: {e}"
            logger.exception(error_msg)
            new_errors.append(error_msg)
            report_update["markdown_report"] = f"# Report Generation Failed\n\nError: {error_msg}"

        # --- Return Updated State --- 
        return {
            **state,
            **report_update,
            "errors": current_errors + [f"{node_name}: {e}" for e in new_errors]
        }

    return node 